{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook prepares the data for LoRA vs full finetuning analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import textwrap\n",
    "import random \n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract context length from df \n",
    "\n",
    "def context_processing(x):\n",
    "    context_ids, token = x[\"in_token_ids\"], x[\"curr_token_id\"]\n",
    "    context = ast.literal_eval(re.split(r'tensor\\(|\\].*', context_ids)[1] + ']')\n",
    "    x[\"context_len\"] = len(context)\n",
    "    x[\"token_in_context\"] = int(token in context)\n",
    "    x[\"uniq_ctxt_tkns_count\"] = len(set(context))\n",
    "    return x\n",
    "    \n",
    "def get_context(x):\n",
    "    return ast.literal_eval(re.split(r'tensor\\(|\\].*', x)[1] + ']')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model_rank = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = f\"../results/pythia-1.4b/lora/r_{lora_model_rank}/lr_2e-4/early_stopping/num_train_4096/bsize_128/seed_1/tkn_freq_probs_best.csv\"\n",
    "lora_df = pd.read_csv(lora_path)\n",
    "\n",
    "full_path = f\"../results/pythia-1.4b/full-ft/lr_2e-6/early_stopping/num_train_4096/bsize_128/tkn_freq_probs_best.csv\"\n",
    "full_df = pd.read_csv(full_path)\n",
    "\n",
    "base_path = f\"../results/pythia-1.4b/base_model/num_train_4096/tkn_freq_probs_base.csv\"\n",
    "base_df = pd.read_csv(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_df = lora_df.apply(context_processing, axis=1)\n",
    "full_df = full_df.apply(context_processing, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_df = lora_df.rename(columns={\n",
    "    \"curr_token_prob\": \"lora_prob\", \n",
    "    \"curr_token_rank\": \"lora_rank\", \n",
    "    \"top_k_pred_tokens\": \"lora_top_k_pred_tokens\", \n",
    "    \"top_k_pred_probs\": \"lora_top_k_pred_probs\"\n",
    "    })\n",
    "full_df = full_df.rename(columns={\n",
    "    \"curr_token_prob\": \"full_prob\", \n",
    "    \"curr_token_rank\": \"full_rank\", \n",
    "    \"top_k_pred_tokens\": \"full_top_k_pred_tokens\", \n",
    "    \"top_k_pred_probs\": \"full_top_k_pred_probs\"\n",
    "    })\n",
    "base_df = base_df.rename(columns={\n",
    "    \"curr_token_prob\": \"base_prob\", \n",
    "    \"curr_token_rank\": \"base_rank\", \n",
    "    \"top_k_pred_tokens\": \"base_top_k_pred_tokens\", \n",
    "    \"top_k_pred_probs\": \"base_top_k_pred_probs\"\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_df_dir = f\"results/data/lora_model/rank/r_{lora_model_rank}/finetuning_data\"\n",
    "base_df_dir = f\"results/data/base_model/finetuning_data\"\n",
    "full_df_dir = f\"results/data/full_model/finetuning_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(lora_df_dir, exist_ok=True)\n",
    "lora_save_path = os.path.join(lora_df_dir, \"lora_data_probs.csv\")\n",
    "\n",
    "os.makedirs(base_df_dir, exist_ok=True)\n",
    "base_save_path = os.path.join(base_df_dir, \"base_data_probs.csv\")\n",
    "\n",
    "os.makedirs(full_df_dir, exist_ok=True)\n",
    "full_save_path = os.path.join(full_df_dir, \"full_data_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "lora_df.to_csv(lora_save_path, index=False)\n",
    "full_df.to_csv(full_save_path, index=False)\n",
    "base_df.to_csv(base_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the processed data\n",
    "lora_df = pd.read_csv(lora_save_path)\n",
    "full_df = pd.read_csv(full_save_path)\n",
    "base_df = pd.read_csv(base_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert string representation of np array to array\n",
    "def parse_array_string(array_str):\n",
    "    try:\n",
    "        cleaned_str = '[' + ', '.join(array_str.strip('[]').split()) + ']'\n",
    "        return ast.literal_eval(cleaned_str)\n",
    "    except:\n",
    "        return []  # Return empty array if parsing fails\n",
    "\n",
    "# Convert array columns - adjust column names as needed\n",
    "array_columns = ['lora_top_k_pred_probs', 'full_top_k_pred_probs', 'base_top_k_pred_probs', 'lora_top_k_pred_tokens', 'full_top_k_pred_tokens', 'base_top_k_pred_tokens']\n",
    "for df in [lora_df, full_df, base_df]:\n",
    "    for col in array_columns:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].apply(parse_array_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_cols = set(lora_df.columns).intersection(set(full_df.columns))\n",
    "full_df.drop(common_cols, axis=1, inplace=True)\n",
    "common_cols = common_cols.intersection(set(base_df.columns))\n",
    "base_df.drop(common_cols, axis=1, inplace=True)\n",
    "df_combined = pd.concat([lora_df, full_df, base_df], axis=1)\n",
    "df_combined[\"full_lora_diff\"] = df_combined.full_prob - df_combined.lora_prob\n",
    "df_combined[\"lora_base_diff\"] = df_combined.lora_prob - df_combined.base_prob\n",
    "df_combined[\"full_base_diff\"] = df_combined.full_prob - df_combined.base_prob\n",
    "\n",
    "df_combined[\"full_lora_tkn_rank_diff\"] = df_combined.full_rank - df_combined.lora_rank\n",
    "df_combined[\"lora_base_tkn_rank_diff\"] = df_combined.lora_rank - df_combined.base_rank\n",
    "df_combined[\"full_base_tkn_rank_diff\"] = df_combined.full_rank - df_combined.base_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_token</th>\n",
       "      <th>seq_id</th>\n",
       "      <th>in_tokens</th>\n",
       "      <th>context_len</th>\n",
       "      <th>token_in_context</th>\n",
       "      <th>uniq_ctxt_tkns_count</th>\n",
       "      <th>prev_token</th>\n",
       "      <th>pmi</th>\n",
       "      <th>curr_token_freq</th>\n",
       "      <th>prev_token_freq</th>\n",
       "      <th>...</th>\n",
       "      <th>base_rank</th>\n",
       "      <th>lora_top_k_pred_tokens</th>\n",
       "      <th>full_top_k_pred_tokens</th>\n",
       "      <th>base_top_k_pred_tokens</th>\n",
       "      <th>lora_top_k_pred_probs</th>\n",
       "      <th>full_top_k_pred_probs</th>\n",
       "      <th>base_top_k_pred_probs</th>\n",
       "      <th>full_lora_tkn_rank_diff</th>\n",
       "      <th>lora_base_tkn_rank_diff</th>\n",
       "      <th>full_base_tkn_rank_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>Ġ@</td>\n",
       "      <td>3747</td>\n",
       "      <td>Mogadishu University ( MU ) is a non</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>Ġnon</td>\n",
       "      <td>-4.023</td>\n",
       "      <td>5438</td>\n",
       "      <td>55</td>\n",
       "      <td>...</td>\n",
       "      <td>32569</td>\n",
       "      <td>[1214, 1108, 428, 24715, 11528, 11073, 5702, 1...</td>\n",
       "      <td>[14, 1108, 11528, 24715, 1214, 428, 2208, 2003...</td>\n",
       "      <td>[14, 11528, 24715, 2208, 2003, 3250, 7338, 374...</td>\n",
       "      <td>[0.962, 0.019, 0.003, 0.001, 0.001, 0.001, 0.0...</td>\n",
       "      <td>[0.598, 0.032, 0.031, 0.031, 0.022, 0.022, 0.0...</td>\n",
       "      <td>[0.911, 0.026, 0.011, 0.004, 0.004, 0.003, 0.0...</td>\n",
       "      <td>4</td>\n",
       "      <td>-32568</td>\n",
       "      <td>-32564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.</td>\n",
       "      <td>2708</td>\n",
       "      <td>Ceratopsia or Ceratopia ( / ˌsɛrəˈtɒpsiə / or...</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>Ġ@</td>\n",
       "      <td>-3.831</td>\n",
       "      <td>1822</td>\n",
       "      <td>5438</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>[15, 14, 13, 1253, 8634, 283, 21549, 15770, 42...</td>\n",
       "      <td>[13, 15, 14, 1157, 904, 23659, 84, 15770, 1939...</td>\n",
       "      <td>[285, 495, 608, 281, 15, 14, 1253, 428, 374, 933]</td>\n",
       "      <td>[0.946, 0.049, 0.003, 0.001, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.823, 0.122, 0.052, 0.001, 0.001, 0.0, 0.0, ...</td>\n",
       "      <td>[0.074, 0.015, 0.014, 0.011, 0.011, 0.01, 0.01...</td>\n",
       "      <td>1</td>\n",
       "      <td>-4</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1107</th>\n",
       "      <td>Ġ5</td>\n",
       "      <td>2652</td>\n",
       "      <td>After the war, the State Government negotiate...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>Ġ(</td>\n",
       "      <td>-3.927</td>\n",
       "      <td>445</td>\n",
       "      <td>2660</td>\n",
       "      <td>...</td>\n",
       "      <td>33</td>\n",
       "      <td>[608, 577, 8073, 8676, 2456, 8255, 8319, 470, ...</td>\n",
       "      <td>[2456, 8319, 8073, 608, 8676, 7584, 8255, 5693...</td>\n",
       "      <td>[2666, 18, 23, 19, 9887, 24, 25, 21, 22, 17]</td>\n",
       "      <td>[0.912, 0.013, 0.009, 0.009, 0.007, 0.007, 0.0...</td>\n",
       "      <td>[0.256, 0.176, 0.129, 0.128, 0.073, 0.061, 0.0...</td>\n",
       "      <td>[0.03, 0.022, 0.02, 0.019, 0.018, 0.016, 0.015...</td>\n",
       "      <td>3</td>\n",
       "      <td>-32</td>\n",
       "      <td>-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>Ġ'</td>\n",
       "      <td>2397</td>\n",
       "      <td>\" Hollywood \" was released as the album</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>Ġalbum</td>\n",
       "      <td>-4.215</td>\n",
       "      <td>4257</td>\n",
       "      <td>468</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>[686, 256, 1214, 346, 434, 4060, 285, 11386, 2...</td>\n",
       "      <td>[434, 686, 346, 4060, 285, 11386, 369, 1214, 2...</td>\n",
       "      <td>[434, 4060, 457, 11386, 273, 369, 37835, 3540,...</td>\n",
       "      <td>[0.878, 0.04, 0.014, 0.013, 0.009, 0.005, 0.00...</td>\n",
       "      <td>[0.499, 0.114, 0.062, 0.038, 0.033, 0.03, 0.02...</td>\n",
       "      <td>[0.889, 0.015, 0.008, 0.008, 0.007, 0.005, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-68</td>\n",
       "      <td>-67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>us</td>\n",
       "      <td>1551</td>\n",
       "      <td>Jason Sudeikis, who played Floyd in this epis...</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>81</td>\n",
       "      <td>f</td>\n",
       "      <td>-4.593</td>\n",
       "      <td>285</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>[316, 1316, 528, 26407, 899, 20191, 3016, 3635...</td>\n",
       "      <td>[1316, 316, 528, 20191, 26407, 375, 265, 2327,...</td>\n",
       "      <td>[1316, 316, 528, 13, 20191, 5123, 47291, 375, ...</td>\n",
       "      <td>[0.952, 0.046, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
       "      <td>[0.799, 0.193, 0.005, 0.001, 0.0, 0.0, 0.0, 0....</td>\n",
       "      <td>[0.857, 0.127, 0.004, 0.001, 0.001, 0.001, 0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     curr_token  seq_id                                          in_tokens  \\\n",
       "1181         Ġ@    3747               Mogadishu University ( MU ) is a non   \n",
       "2             .    2708   Ceratopsia or Ceratopia ( / ˌsɛrəˈtɒpsiə / or...   \n",
       "1107         Ġ5    2652   After the war, the State Government negotiate...   \n",
       "763          Ġ'    2397            \" Hollywood \" was released as the album   \n",
       "699          us    1551   Jason Sudeikis, who played Floyd in this epis...   \n",
       "\n",
       "      context_len  token_in_context  uniq_ctxt_tkns_count prev_token    pmi  \\\n",
       "1181           12                 0                    12       Ġnon -4.023   \n",
       "2             116                 0                    83         Ġ@ -3.831   \n",
       "1107           36                 0                    32         Ġ( -3.927   \n",
       "763             8                 0                     7     Ġalbum -4.215   \n",
       "699           108                 0                    81          f -4.593   \n",
       "\n",
       "      curr_token_freq  prev_token_freq  ...  base_rank  \\\n",
       "1181             5438               55  ...      32569   \n",
       "2                1822             5438  ...          5   \n",
       "1107              445             2660  ...         33   \n",
       "763              4257              468  ...         69   \n",
       "699               285              141  ...          2   \n",
       "\n",
       "                                 lora_top_k_pred_tokens  \\\n",
       "1181  [1214, 1108, 428, 24715, 11528, 11073, 5702, 1...   \n",
       "2     [15, 14, 13, 1253, 8634, 283, 21549, 15770, 42...   \n",
       "1107  [608, 577, 8073, 8676, 2456, 8255, 8319, 470, ...   \n",
       "763   [686, 256, 1214, 346, 434, 4060, 285, 11386, 2...   \n",
       "699   [316, 1316, 528, 26407, 899, 20191, 3016, 3635...   \n",
       "\n",
       "                                 full_top_k_pred_tokens  \\\n",
       "1181  [14, 1108, 11528, 24715, 1214, 428, 2208, 2003...   \n",
       "2     [13, 15, 14, 1157, 904, 23659, 84, 15770, 1939...   \n",
       "1107  [2456, 8319, 8073, 608, 8676, 7584, 8255, 5693...   \n",
       "763   [434, 686, 346, 4060, 285, 11386, 369, 1214, 2...   \n",
       "699   [1316, 316, 528, 20191, 26407, 375, 265, 2327,...   \n",
       "\n",
       "                                 base_top_k_pred_tokens  \\\n",
       "1181  [14, 11528, 24715, 2208, 2003, 3250, 7338, 374...   \n",
       "2     [285, 495, 608, 281, 15, 14, 1253, 428, 374, 933]   \n",
       "1107       [2666, 18, 23, 19, 9887, 24, 25, 21, 22, 17]   \n",
       "763   [434, 4060, 457, 11386, 273, 369, 37835, 3540,...   \n",
       "699   [1316, 316, 528, 13, 20191, 5123, 47291, 375, ...   \n",
       "\n",
       "                                  lora_top_k_pred_probs  \\\n",
       "1181  [0.962, 0.019, 0.003, 0.001, 0.001, 0.001, 0.0...   \n",
       "2     [0.946, 0.049, 0.003, 0.001, 0.0, 0.0, 0.0, 0....   \n",
       "1107  [0.912, 0.013, 0.009, 0.009, 0.007, 0.007, 0.0...   \n",
       "763   [0.878, 0.04, 0.014, 0.013, 0.009, 0.005, 0.00...   \n",
       "699   [0.952, 0.046, 0.001, 0.0, 0.0, 0.0, 0.0, 0.0,...   \n",
       "\n",
       "                                  full_top_k_pred_probs  \\\n",
       "1181  [0.598, 0.032, 0.031, 0.031, 0.022, 0.022, 0.0...   \n",
       "2     [0.823, 0.122, 0.052, 0.001, 0.001, 0.0, 0.0, ...   \n",
       "1107  [0.256, 0.176, 0.129, 0.128, 0.073, 0.061, 0.0...   \n",
       "763   [0.499, 0.114, 0.062, 0.038, 0.033, 0.03, 0.02...   \n",
       "699   [0.799, 0.193, 0.005, 0.001, 0.0, 0.0, 0.0, 0....   \n",
       "\n",
       "                                  base_top_k_pred_probs  \\\n",
       "1181  [0.911, 0.026, 0.011, 0.004, 0.004, 0.003, 0.0...   \n",
       "2     [0.074, 0.015, 0.014, 0.011, 0.011, 0.01, 0.01...   \n",
       "1107  [0.03, 0.022, 0.02, 0.019, 0.018, 0.016, 0.015...   \n",
       "763   [0.889, 0.015, 0.008, 0.008, 0.007, 0.005, 0.0...   \n",
       "699   [0.857, 0.127, 0.004, 0.001, 0.001, 0.001, 0.0...   \n",
       "\n",
       "      full_lora_tkn_rank_diff  lora_base_tkn_rank_diff  \\\n",
       "1181                        4                   -32568   \n",
       "2                           1                       -4   \n",
       "1107                        3                      -32   \n",
       "763                         1                      -68   \n",
       "699                         1                       -1   \n",
       "\n",
       "      full_base_tkn_rank_diff  \n",
       "1181                   -32564  \n",
       "2                          -3  \n",
       "1107                      -29  \n",
       "763                       -67  \n",
       "699                         0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_diffs = df_combined.sort_values(\"full_lora_diff\")\n",
    "df_selected = sorted_diffs[[\"seq_id\", \"in_tokens\", \"context_len\", \"token_in_context\", \"uniq_ctxt_tkns_count\", \"prev_token\", \"curr_token\", \"pmi\", \"curr_token_freq\", \"prev_token_freq\", \"pair_token_freq\", \"lora_prob\", \"full_prob\", \"base_prob\", \"full_lora_diff\", \"lora_base_diff\", \"full_base_diff\", \"lora_rank\", \"full_rank\", \"base_rank\", \"lora_top_k_pred_tokens\", \"full_top_k_pred_tokens\", \"base_top_k_pred_tokens\", \"lora_top_k_pred_probs\", \"full_top_k_pred_probs\", \"base_top_k_pred_probs\", \"full_lora_tkn_rank_diff\", \"lora_base_tkn_rank_diff\", \"full_base_tkn_rank_diff\"]]\n",
    "finetune_df = df_selected\n",
    "finetune_df = finetune_df.dropna().reset_index(drop=True)\n",
    "df_selected = df_selected[(df_selected[\"pmi\"] > -4.75) & (df_selected[\"pmi\"] < -3.75)]\n",
    "# find unique pairs of w_{i-1}, w_i\n",
    "agg_fns = {c: 'first' for c in df_selected.columns if c not in [\"curr_token\"]}\n",
    "agg_fns[\"full_lora_diff\"] = \"min\"\n",
    "df_uniq = df_selected.groupby([\"curr_token\"]).agg(agg_fns).reset_index().sort_values(\"full_lora_diff\")\n",
    "\n",
    "top_100 = df_uniq[:100]\n",
    "top_100.loc[:, [\"seq_id\", \"pmi\", \"curr_token_freq\", \"lora_prob\", \"full_prob\", \"base_prob\", \"full_lora_diff\", \"lora_base_diff\", \"full_base_diff\"]] = top_100[[\"seq_id\", \"pmi\", \"curr_token_freq\", \"lora_prob\", \"full_prob\", \"base_prob\", \"full_lora_diff\", \"lora_base_diff\", \"full_base_diff\"]].round(3)\n",
    "top_100.to_csv(f\"results/examples_ft_pt/rank/r_{lora_model_rank}/finetune_data_100.csv\", index=False)\n",
    "top_100.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_df.to_csv(f\"results/data/lora_model/rank/r_{lora_model_rank}/finetuning_data/finetune_data_probs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_path = \"../results/pythia-1.4b/lora/r_16/lr_2e-4/early_stopping/pretraining/tkn_freq_probs_best.csv\"\n",
    "lora_df = pd.read_csv(lora_path)\n",
    "full_path = \"../results/pythia-1.4b/full-ft/lr_2e-6/early_stopping/pretraining/tkn_freq_probs_best.csv\"\n",
    "full_df = pd.read_csv(full_path)\n",
    "base_path = \"../results/pythia-1.4b/base_model/pretraining/tkn_freq_probs_base.csv\"\n",
    "base_df = pd.read_csv(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                          tensor([1413], dtype=torch.int32)\n",
       "1                    tensor([1413,   27], dtype=torch.int32)\n",
       "2              tensor([1413,   27,   49], dtype=torch.int32)\n",
       "3          tensor([1413,   27,   49,  363], dtype=torch.i...\n",
       "4          tensor([1413,   27,   49,  363, 2721], dtype=t...\n",
       "                                 ...                        \n",
       "2097148    tensor([  273, 32212,   267,  6943, 18334,  11...\n",
       "2097149    tensor([32212,   267,  6943, 18334,  1119, 313...\n",
       "2097150    tensor([  267,  6943, 18334,  1119, 31388,    ...\n",
       "2097151    tensor([ 6943, 18334,  1119, 31388,    71,   5...\n",
       "2097152    tensor([18334,  1119, 31388,    71,   579,   9...\n",
       "Name: in_token_ids, Length: 2097153, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lora_df[\"in_token_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_df = lora_df.dropna().reset_index(drop=True)\n",
    "cp = ContextProcessor(lora_df)\n",
    "lora_df[\"context_len\"]= cp.get_context_len()\n",
    "lora_df[\"token_in_context\"]= cp.is_token_in_context()\n",
    "lora_df[\"uniq_ctxt_tkns_count\"]= cp.uniq_ctxt_tkns_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 1111028/2096781 [03:07<02:40, 6136.78it/s]IOStream.flush timed out\n",
      "100%|██████████| 2096781/2096781 [06:02<00:00, 5792.12it/s] \n"
     ]
    }
   ],
   "source": [
    "full_df = full_df.dropna().reset_index(drop=True)\n",
    "cp = ContextProcessor(full_df)\n",
    "full_df[\"context_len\"]= cp.get_context_len()\n",
    "full_df[\"token_in_context\"]= cp.is_token_in_context()\n",
    "full_df[\"uniq_ctxt_tkns_count\"]= cp.uniq_ctxt_tkns_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_df = lora_df.rename(columns={\"curr_token_prob\": \"lora_prob\"})\n",
    "full_df = full_df.rename(columns={\"curr_token_prob\": \"full_prob\"})\n",
    "base_df = base_df.rename(columns={\"curr_token_prob\": \"base_prob\"})\n",
    "common_cols = set(lora_df.columns).intersection(set(full_df.columns))\n",
    "full_df.drop(common_cols, axis=1, inplace=True)\n",
    "common_cols = common_cols.intersection(set(base_df.columns))\n",
    "base_df.drop(common_cols, axis=1, inplace=True)\n",
    "df_combined = pd.concat([lora_df, full_df, base_df], axis=1)\n",
    "df_combined[\"full_lora_diff\"] = df_combined.full_prob - df_combined.lora_prob\n",
    "df_combined[\"lora_base_diff\"] = df_combined.lora_prob - df_combined.base_prob\n",
    "df_combined[\"full_base_diff\"] = df_combined.full_prob - df_combined.base_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_diffs = df_combined.sort_values(\"full_lora_diff\", ascending=False)\n",
    "df_selected = sorted_diffs[[\"in_tokens\", \"context_len\", \"token_in_context\", \"uniq_ctxt_tkns_count\", \"prev_token\", \"curr_token\", \"pmi\", \"curr_token_freq\", \"prev_token_freq\", \"pair_token_freq\", \"lora_prob\", \"full_prob\", \"base_prob\", \"full_lora_diff\", \"lora_base_diff\", \"full_base_diff\"]]\n",
    "pretrain_df = df_selected\n",
    "pretrain_df = pretrain_df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>curr_token</th>\n",
       "      <th>in_tokens</th>\n",
       "      <th>context_len</th>\n",
       "      <th>token_in_context</th>\n",
       "      <th>uniq_ctxt_tkns_count</th>\n",
       "      <th>prev_token</th>\n",
       "      <th>pmi</th>\n",
       "      <th>curr_token_freq</th>\n",
       "      <th>prev_token_freq</th>\n",
       "      <th>pair_token_freq</th>\n",
       "      <th>lora_prob</th>\n",
       "      <th>full_prob</th>\n",
       "      <th>base_prob</th>\n",
       "      <th>full_lora_diff</th>\n",
       "      <th>lora_base_diff</th>\n",
       "      <th>full_base_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>PEC</td>\n",
       "      <td>and no diagonal that accepted 2 inch eyepiece...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>Ċ</td>\n",
       "      <td>-4.907</td>\n",
       "      <td>27.0</td>\n",
       "      <td>79130.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.949</td>\n",
       "      <td>0.051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>-</td>\n",
       "      <td>iance occurred when light passed from air to w...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>ref</td>\n",
       "      <td>-4.013</td>\n",
       "      <td>22036.0</td>\n",
       "      <td>1195.0</td>\n",
       "      <td>30106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>0.985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>107</td>\n",
       "      <td>2)     0.0005 (15)    0.0052 (16)    0.0093 (1...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>.</td>\n",
       "      <td>-4.589</td>\n",
       "      <td>36.0</td>\n",
       "      <td>72634.0</td>\n",
       "      <td>1680.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>-0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10475</th>\n",
       "      <td>gre</td>\n",
       "      <td>outrun the hare.\\n\\nIn the night\\n\\nhis eyes ...</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Ċ</td>\n",
       "      <td>-4.600</td>\n",
       "      <td>22.0</td>\n",
       "      <td>79130.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.198</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9333</th>\n",
       "      <td>edge</td>\n",
       "      <td>_Tapiola_\\n\\nHe is no more dead than Finland ...</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Ċ</td>\n",
       "      <td>-4.274</td>\n",
       "      <td>22.0</td>\n",
       "      <td>79130.0</td>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.677</td>\n",
       "      <td>0.323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      curr_token                                          in_tokens  \\\n",
       "4983         PEC   and no diagonal that accepted 2 inch eyepiece...   \n",
       "566            -  iance occurred when light passed from air to w...   \n",
       "966          107  2)     0.0005 (15)    0.0052 (16)    0.0093 (1...   \n",
       "10475        gre   outrun the hare.\\n\\nIn the night\\n\\nhis eyes ...   \n",
       "9333        edge   _Tapiola_\\n\\nHe is no more dead than Finland ...   \n",
       "\n",
       "       context_len  token_in_context  uniq_ctxt_tkns_count prev_token    pmi  \\\n",
       "4983         129.0               0.0                 102.0          Ċ -4.907   \n",
       "566          129.0               1.0                  74.0        ref -4.013   \n",
       "966          129.0               0.0                  38.0          . -4.589   \n",
       "10475         67.0               0.0                  44.0          Ċ -4.600   \n",
       "9333         129.0               0.0                  86.0          Ċ -4.274   \n",
       "\n",
       "       curr_token_freq  prev_token_freq  pair_token_freq  lora_prob  \\\n",
       "4983              27.0          79130.0            999.0        0.0   \n",
       "566            22036.0           1195.0          30106.0        0.0   \n",
       "966               36.0          72634.0           1680.0        0.0   \n",
       "10475             22.0          79130.0           1106.0        0.0   \n",
       "9333              22.0          79130.0           1533.0        0.0   \n",
       "\n",
       "       full_prob  base_prob  full_lora_diff  lora_base_diff  full_base_diff  \n",
       "4983         1.0      0.949             1.0          -0.949           0.051  \n",
       "566          1.0      0.015             1.0          -0.015           0.985  \n",
       "966          1.0      1.000             1.0          -1.000          -0.000  \n",
       "10475        1.0      0.198             1.0          -0.198           0.802  \n",
       "9333         1.0      0.677             1.0          -0.677           0.323  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_selected = pretrain_df[(pretrain_df[\"pmi\"] > -5) & (pretrain_df[\"pmi\"] < -4)]\n",
    "\n",
    "# find unique pairs of w_{i-1}, w_i\n",
    "agg_fns = {c: 'first' for c in pretrain_df.columns if c not in [\"curr_token\"]}\n",
    "agg_fns[\"full_lora_diff\"] = \"max\"\n",
    "df_uniq = pretrain_df.groupby([\"curr_token\"]).agg(agg_fns).reset_index().sort_values(\"full_lora_diff\", ascending=False)\n",
    "\n",
    "top_100 = df_uniq[:100]\n",
    "\n",
    "top_100.loc[:, [\"pmi\", \"curr_token_freq\", \"lora_prob\", \"full_prob\", \"base_prob\", \"full_lora_diff\", \"lora_base_diff\", \"full_base_diff\"]] = top_100[[\"pmi\", \"curr_token_freq\", \"lora_prob\", \"full_prob\", \"base_prob\", \"full_lora_diff\", \"lora_base_diff\", \"full_base_diff\"]].round(3)\n",
    "top_100.to_csv(\"results/examples_ft_pt/pretrain_data_100.csv\", index=False)\n",
    "top_100.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge pretrain/finetune data with finetune/pretrain token frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_data_stats = pretrain_df[[\"prev_token\", \"curr_token\", \"curr_token_freq\", \"prev_token_freq\", \"pair_token_freq\", \"pmi\"]]\n",
    "ft_data_stats = finetune_df[[\"prev_token\", \"curr_token\", \"curr_token_freq\", \"prev_token_freq\", \"pair_token_freq\", \"pmi\"]]\n",
    "\n",
    "pt_data_stats = pt_data_stats.add_prefix('pt_').drop_duplicates().reset_index(drop=True)\n",
    "pt_data_stats = pt_data_stats.rename(columns={\"pt_prev_token\": \"prev_token\", \"pt_curr_token\": \"curr_token\"})\n",
    "ft_data_stats = ft_data_stats.add_prefix('ft_').drop_duplicates().reset_index(drop=True)\n",
    "ft_data_stats = ft_data_stats.rename(columns={\"ft_prev_token\": \"prev_token\", \"ft_curr_token\": \"curr_token\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_pairs = pt_data_stats[[\"curr_token\", \"prev_token\", \"pt_pmi\"]]\n",
    "ft_pairs = ft_data_stats[[\"curr_token\", \"prev_token\", \"ft_pmi\"]]\n",
    "\n",
    "common_pairs = pd.merge(pt_pairs, ft_pairs, on=[\"curr_token\", \"prev_token\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_token_freq = pt_data_stats[[\"curr_token\", \"pt_curr_token_freq\"]]\n",
    "pt_token_freq = pt_token_freq.drop_duplicates().reset_index(drop=True)\n",
    "finetune_df_merged = pd.merge(finetune_df, pt_token_freq, on=[\"curr_token\"], how=\"left\")\n",
    "finetune_df_merged[\"pt_curr_token_freq\"] = finetune_df_merged[\"pt_curr_token_freq\"].fillna(0)\n",
    "finetune_df_merged = finetune_df_merged.dropna().reset_index(drop=True)\n",
    "\n",
    "\n",
    "ft_token_freq = ft_data_stats[[\"curr_token\", \"ft_curr_token_freq\"]]\n",
    "ft_token_freq = ft_token_freq.drop_duplicates().reset_index(drop=True)\n",
    "pretrain_df_merged = pd.merge(pretrain_df, ft_token_freq, on=[\"curr_token\"], how=\"left\")\n",
    "pretrain_df_merged[\"pt_curr_token_freq\"] = pretrain_df_merged[\"ft_curr_token_freq\"].fillna(0)\n",
    "pretrain_df_merged = pretrain_df_merged.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetune_df_merged.to_csv(\"results/data/finetune_data_probs.csv\", index=False)\n",
    "pretrain_df_merged.to_csv(\"results/data/pretrain_data_probs.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lora_mem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
